compatibility:
  log_path:
  ckpt_id:
  model:
    architecture: "fcn"
    hidden_layers: [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048]

logging:
  seed : 42
  exp : 'exp'
  doc : 'doc'
  comment: ''
  verbose_logger: info
  verbose_stderr: info
  image_folder: 'image_folder'
baryproj:
  log_path:
  ckpt_id: # use final ckpt
  model:
    architecture: "res"
    normalization: InstanceNorm++
    nonlinearity: elu
    ngf: 48

source:
  data:
    dataset: "CELEBA-32px-even"
    image_size: 64
    channels: 3
    logit_transform: false
    uniform_dequantization: false
    gaussian_dequantization: false
    random_flip: true
    rescaled: false
    num_workers: 4

target:
  data:
    dataset: "CELEBA-odd"
    image_size: 64
    channels: 3
    logit_transform: false
    uniform_dequantization: false
    gaussian_dequantization: false
    random_flip: true
    rescaled: false
    num_workers: 4

transport:
  regularization: "entropy" # l2, entropy
  coeff: 0.1
  cost: "mean-l2-sq"

ncsn:
  sampling:
    log_path: pretrained/ncsn/celeba
    sources_per_batch: 250
    samples_per_source: 1
    data_init: true
    step_lr: 0.0000015
    n_steps_each: 5
    ckpt_id: 210000
    final_only: true
    fid: true
    denoise: true
    num_samples4fid: 5000
    inpainting: false
    interpolation: false
    n_interpolations: 15

  fast_fid:
    batch_size: 1000
    num_sources: 1000
    step_lr: 0.0000033
    n_steps_each: 5
    begin_ckpt: 5000
    end_ckpt: 210000
    verbose: false
    ensemble: false

  model:
    sigma_begin: 90
    num_classes: 500
    ema: true
    ema_rate: 0.999
    spec_norm: false
    sigma_dist: geometric
    sigma_end: 0.01
    normalization: InstanceNorm++
    nonlinearity: elu
    ngf: 128
    
 n_gpu: 2